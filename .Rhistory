, alternative = 'two.sided'
, paired = TRUE
, conf.level = .95
)
AvgDiff <- mean(SkiExperts$Actual - SkiExperts$Imaginary)
SdDiff <- sd(SkiExperts$Actual - SkiExperts$Imaginary)
nDiff <- dim(SkiExperts)[1] #number of rows = number of observations
tsum.test(mean.x = AvgDiff
, s.x = SdDiff
, n.x = nDiff
, alternative = 'two.sided'
, mu = 0
, conf.level = .95)
head(gss_cat)
df <- gss_cat %>%
filter(!is.na(tvhours))
dim(df)
unique(df$relig)
df <- df %>%
mutate(relig = case_when(
relig == "Don't know" ~ "Atheist/agnostic"
, relig == "None" ~ "Atheist/agnostic"
, relig == "No answer" ~ "Atheist/agnostic"
, .default = relig
))
df %>%
group_by(relig) %>%
summarize(n = n()
, meanTV = mean(tvhours)
, sdTV = sd(tvhours)) %>%
arrange(desc(n))
test <- aov(tvhours ~ relig, data = df)
summary(test)
bookdown::render_book()
library(tidyverse)
library(knitr)
library(openintro)
library(infer)
library(patchwork)
set.seed(1187)
pHat <- sum(gss2010$degree == "LT HIGH SCHOOL") / length(gss2010$degree)
pHat
# Take sample
sample2 <- sample( gss2010$degree, size = 2044, replace = TRUE)
#Find proportion of high school dropouts
pHat2 <- sum(sample2 == "LT HIGH SCHOOL") / length(sample2)
pHat2
simulated_sampling_distr <- gss2010 %>%
rep_sample_n(size = 2044, reps = 5000, replace = TRUE) %>%
mutate( degree = if_else(degree == "LT HIGH SCHOOL", "LT HIGH SCHOOL", "other")) %>%
count(degree) %>%
mutate(p_hat = n / sum(n)) %>%
filter( degree == "LT HIGH SCHOOL")
head(simulated_sampling_distr)
ggplot(simulated_sampling_distr, aes(x = p_hat)) +
geom_histogram(bins = 15, color = "black", fill = "steelblue") +
labs(title = "Distribution of sample proportions, n = 2044",
subtitle = "Estimating SE for 2010 proportion of Americans without a HS diploma",
x = "Sample proportion, p-hat")
#average sample proportion
mean(simulated_sampling_distr$p_hat)
sd(simulated_sampling_distr$p_hat)
sampling_dist2 <- gss2010 %>%
rep_sample_n(size = 100, reps = 5000, replace = TRUE) %>%
mutate( degree = if_else(degree == "LT HIGH SCHOOL", "LT HIGH SCHOOL", "other")) %>%
count(degree) %>%
mutate(p_hat = n / sum(n)) %>%
filter( degree == "LT HIGH SCHOOL")
head(sampling_dist2)
ggplot(sampling_dist2, aes(x = p_hat)) +
geom_histogram(bins = 15, color = "black", fill = "steelblue") +
labs(title = "Distribution of sample proportions, n = 100",
subtitle = "Estimating SE for 2010 proportion of Americans without a HS diploma",
x = "Sample proportion, p-hat")
mean(sampling_dist2$p_hat)
sd(sampling_dist2$p_hat)
pHat
SE <- sd(simulated_sampling_distr$p_hat)
SE
CI <- pHat + c(-1,1)*2*SE
CI
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.4, .45))+
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.55, .6)) +
labs(title = "P-value of two-sided hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.55, .6)) +
labs(title = "P-value of one-sided upper hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.4, .55)) +
labs(title = "P-value of one-sided lower hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
# generates results from 5000 binomial experiments w/ probability of
# success = .1 and sample size of n = 2044, returns sample proportion.
null_dist <- tibble(p_hat = rbinom(5000, 2044, .1)/2044)
# center of distribution
mean(null_dist$p_hat)
# standard error
SE <- sd(null_dist$p_hat)
SE
ggplot(null_dist, aes(x = p_hat)) +
geom_histogram(bins = 15, color = "black", fill = "steelblue") +
geom_vline(xintercept = pHat, color = "red") +
labs(title = "Null distribution with p = .1 and n = 2044, pHat = .149",
x = "Sample proportion, p-hat")
# count the number of simulated samples with proportions at least as large as
# our actual sample proportion, divide by number of samples in simulated dist.
pValue <- sum(null_dist$p_hat >= pHat ) / length(null_dist$p_hat)
pValue
ggplot(data.frame(x = c(-3,3)), aes(x = x)) +
stat_function(fun = dnorm,
geom = "line") +
stat_function(fun = dnorm,
geom = "area",
fill = "steelblue",
xlim = c(-1.96, 1.96))+
labs(title = "What bounds give us a central area of .95?",
x = "Z", y = "")
qnorm(.025, lower.tail = FALSE)
cvTable <- tibble( conf.level = c(.9, .95, .98, .99),
crit.val = qnorm( (1 - conf.level)/2, lower.tail =F))
cvTable
# components of CI
pHat <- sum( gss2010$degree == "LT HIGH SCHOOL") / length(gss2010$degree)
SE <- sqrt(pHat*(1-pHat)/length(gss2010$degree))
zCrit <- qnorm( (1 - .95)/2, lower.tail = FALSE)
# CI
pHat + c(-1,1)*zCrit*SE
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.4, .45))+
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.55, .6)) +
labs(title = "P-value of two-sided hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
pNull <- .5
SE <- sqrt(pNull*(1 - pNull)/200)
pHat <- .55
pVal <- 2*pnorm(.55, mean = pNull, sd = SE, lower.tail = F)
pVal
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.55, .6)) +
labs(title = "P-value of one-sided upper hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
pNull <- .5
SE <- sqrt(pNull*(1 - pNull)/200)
pHat <- .55
pVal <- pnorm(.55, mean = pNull, sd = SE, lower.tail = F)
pVal
#set mean and sd of normal sampling dist.
args <- c(mean = .5, sd = sqrt(.5*.5/200))
#plotting
ggplot(data.frame(x = c(.4,.6)), aes(x = x)) +
stat_function(fun = dnorm,
args = args,
geom = "line") +
stat_function(fun = dnorm,
args = args,
geom = "area",
fill = "steelblue",
xlim = c(.4, .55)) +
labs(title = "P-value of one-sided lower hypothesis test",
subtitle = "null prop. = .5, p_hat = .55, n = 200",
x = "sample proprotion",
y = "")
pNull <- .5
SE <- sqrt(pNull*(1 - pNull)/200)
pHat <- .55
pVal <- pnorm(.55, mean = pNull, sd = SE)
pVal
n <- length(gss2010$degree)
n
pHat <- sum(gss2010$degree == "LT HIGH SCHOOL")/n
pHat
pNull <- .1
# will return a logical, T/F
n*pNull >= 10
n*(1 - pNull) >= 10
SE <- sqrt(pNull*(1- pNull)/n)
pValue <- pnorm(pHat, mean = pNull, sd = SE, lower.tail = F)
pValue
slice_sample(cancer_in_dogs, n = 4)
sumTab <- table(cancer_in_dogs$response, cancer_in_dogs$order)
sumTab %>% kable()
n1 <- sum(sumTab[,1])
n2 <- sum(sumTab[,2])
pHat1 <- sumTab[1,1] / n1
pHat2 <- sumTab[1,2] / n2
c(pHat1, pHat2)
pDiff <- pHat1 - pHat2
pDiff
SE <- sqrt(pHat1*(1- pHat1)/n1 +  pHat2*(1- pHat2)/n2)
SE
zCrit <- qnorm( (1-.95)/2, lower.tail = F)
ciDiff <- pDiff + c(-1, 1)*zCrit*SE
ciDiff
sumTab %>% kable()
pPool <- sum(sumTab[1,])/sum(sumTab)
pPool
c( n1*pPool, n1*(1-pPool))
c( n2*pPool, n2*(1-pPool))
SE <- sqrt( pPool*(1-pPool)/n1 + pPool*(1-pPool)/n2)
SE
pHat1 <- sumTab[1,1] / n1
pHat2 <- sumTab[1,2] / n2
pDiff <- pHat1 - pHat2
pDiff
Z <- pDiff / SE
Z
pVal <- 2*pnorm(Z,lower.tail = FALSE)
pVal
table(sp500_seq$race)
table(smoking$smoke, smoking$marital_status)
ggplot(tibble(x = c(0, 18)), aes(x = x)) +
geom_function(fun = dchisq,
args = list(df = 5)) +
stat_function(fun = dchisq,
args = list(df = 5),
geom = "area",
xlim = c(6.2, 18),
fill = "steelblue") +
labs( x = "chi-squared", y = "",
title = "Chi-squared distribution with df = 5",
subtitle = "p-value for chi-squared = 6.2 shaded")
pchisq(6.2, df = 5, lower.tail=FALSE)
spTable <- table(sp500_seq$race)
spTable
sp500_1950_2018 %>%
filter( as.character(Date) >= '1990' &
as.character(Date) <= '2012') %>%
mutate(dir = if_else( Close > Open, TRUE, FALSE)) %>%
summarize( upProb = sum(dir)/length(dir))
# total number of up-to-up runs
n <-sum(spTable)
#list of factors
days <- c(1:6, "7+")
#probability/proportion of each factor level
probs <- c( dgeom(0:5,.531), pgeom(5, .531, lower.tail = F))
# expected counts
expected <- n*probs
expected
# display all of the above in a horizontally organized table
t( tibble(days, prob = round(probs, 3), expected = round(expected, 3))) %>% kable()
# each individual squared z-score
(spTable - expected)^2/expected
# test stat
chi.sq <- sum((spTable - expected)^2/expected)
chi.sq
pchisq(chi.sq, df = 6, lower.tail = FALSE)
(spTable - expected)/sqrt(expected)
observed <- table(smoking$smoke, smoking$marital_status)
observed
n <- sum(observed)
row1 <- sum(observed[1,])
column1 <- sum(observed[,1])
c(n, row1, column1)
exp11 <- row1*column1/n
exp11
(observed[1,1]- exp11)^2/exp11
# define an matrix with the right dimensions of all zeroes
expected <- matrix( rep(0, prod(dim(observed))),
nrow = dim(observed)[1],
ncol = dim(observed)[2])
# iterate over all rows
for(i in 1:dim(observed)[1]){
#iterage over all columns
for(j in 1:dim(observed)[2]){
#update i,j-th entry with expected count
expected[i,j] <- sum(observed[i,])*sum(observed[,j])/sum(observed)
}
}
expected
(observed - expected)^2/expected
chi <- sum((observed - expected)^2/expected)
chi
pchisq(chi, df = 4, lower.tail = F)
(observed - expected)/sqrt(expected)
df <- data.frame(x = c(0, 7.5))
popPlot <- ggplot( data = df,
aes(x = x)) +
stat_function(fun = dgamma
, args = list(shape = 2, scale = 2)) +
labs(
title = "Income distribution of Flathead County residents"
, x = "Annual income"
, y = "Density"
) +
scale_x_continuous(breaks = c(0, 4)
, labels = c("0", "50k")) +
theme(axis.ticks.y = element_blank(),
axis.text.y = element_blank())
sampPlot <- ggplot(data = df,
aes(x = x)) +
stat_function(fun = dnorm
, args = list(mean = 4, sd = sqrt(8/ 100))
, color = "red") +
labs(
title = "Distribution of sample average income"
, subtitle = "n = 100"
, x = "Average annual income"
, y = "Density"
) +
scale_x_continuous(breaks = c(0, 4)
, labels = c("0", "50k")) +
theme(axis.ticks.y = element_blank(),
axis.text.y = element_blank())
popPlot + sampPlot
ggplot(faithful, aes(x = waiting)) +
geom_histogram(color = "black"
, fill = "steelblue"
, bins = 20) +
labs( title = "Wait time between Yellowstone eruptions"
, subtitle = "n = 272")
summary(faithful$waiting)
(summary(faithful$waiting) - mean(faithful$waiting))/sd(faithful$waiting)
ggplot(women, aes(x = height)) +
geom_histogram(color = "black"
, fill = "steelblue"
, bins = 7) +
labs( title = "Height of American women in 1975"
, subtitle = "n = 15")
summary(women$height)
(summary(women$height) - mean(women$height))/sd(women$height)
n <- length(faithful$waiting)
xBar <- mean(faithful$waiting)
s <- sd(faithful$waiting)
SE <- s / sqrt(n)
tStar <- qt( (1 - .95)/2, df = n-1, lower.tail = FALSE)
tStar
cI <- xBar + c(-1,1)*tStar*SE
cI
n <- length(women$height)
xBar <- mean(women$height)
s <- sd(women$height)
SE <- s / sqrt(n)
tStar <- qt( (1 - .95)/2, df = n-1, lower.tail = FALSE)
tStar
cI <- xBar + c(-1,1)*tStar*SE
cI
n <- length(women$height)
xBar <- mean(women$height)
s <- sd(women$height)
SE <- s / sqrt(n)
#printing the calculated values
c(n = n, xBar = xBar, s = s, SE = SE)
t <- (xBar - 64.4)/SE
t
pVal <- pt(t, df = 15 - 1, lower.tail = F)
pVal
n <- length(faithful$waiting)
xBar <- mean(faithful$waiting)
s <- sd(faithful$waiting)
SE <- s / sqrt(n)
#printing the calculated values
c(n = n, xBar = xBar, s = s, SE = SE)
t <- (xBar - 75)/SE
t
pVal <- 2*pt(t, df = n-1)
unique(gss2010$grass)
mj <- gss2010 %>%
filter(!is.na(hrs1) & !is.na(grass)) %>% #select only rows with non-null values in hrs1 and grass
select(grass, hrs1)
?select
mj <- gss2010 %>%
filter(!is.na(hrs1) & !is.na(grass)) %>% #select only rows with non-null values in hrs1 and grass
dplyr::select(grass, hrs1)
bookdown::render_book()
bookdown::render_book()
LETTERS
LETTERS[1:5]
rep(LETTERS[1:5], 4)
sort(rep(LETTERS[1:5], 4))
type <- sort(rep(LETTERS[1:5], 4))
type
?select
bookdown::render_book()
bookdown::render_book()
grp <- sort(rep(letters[1:3], 6))
grp
tmp <- c(98.3,97.2,97.3,98.2,98.3,98.7, 99.2,99,99.1,98.5,98,98.9,97,97.2,97.4,97.4,97.8,98.1)
test$coefficients
sort(unique(df$relig))
2.718232044 - 0.335515995
lm(tvhours ~ relig, data = df)
lm(tvhours ~ relig, data = df) %>%
summary()
msu = round(rnorm(10, mean = 82, sd = 4))
um = round(rnorm(10, mean = 79, sd = 4))
fvcc = round(rnorm(10, mean = 84, sd = 4))
df <- tibble( msu = msu, um = um, fvcc = fvcc)
df %>% kable()
view(df)
df %>%
pivot_longer(1:3)
?pivot_longer
df %>%
pivot_longer(cols = 1:3)
, values_to = 'score)
df %>%
pivot_longer(cols = 1:3 #selects columns 1-3 for the values
, names_to = 'school' # the name of the new column
, values_to = 'score')
head(df)
df <- df %>%
pivot_longer(cols = 1:3 #selects columns 1-3 for the values
, names_to = 'school' # the name of the new column
, values_to = 'score')
head(df)
# store each column as a list of numbers named evocatively
msu <- c(85, 86, 86, 78, 88, 83, 82, 86, 83, 77)
um <- c(80, 78, 79, 82, 76, 78, 74, 87, 74, 76)
fvcc <- c(83, 86, 83, 88, 85, 86, 90, 86, 83, 83)
# now make one long list of numbers
scores <- c(msu, um, fvcc)
# now make a list of values for your categorical variable
# this should respect the order of the lists you made above
school <- c( rep("msu", 10), rep("um", 10), rep("fvcc", 10))
# now make a dataframe/tibble with these two lists as columns.
df <- tibble( school, scores)
head(df)
aov(scores ~ school, data = df) %>%
summary()
results %>%  summary()
results <- aov(scores ~ school, data = df)
results %>%  summary()
results$coefficients
bookdown::render_book()
859 +
1381 +
57
859 +
1381
10 +
435 +
516
859 +
1381 +
57
1545 + 57
432 + 519
516+57
445+2240
519+57
432+1545
